# 多臂老虎机

## 问题简介

多臂老虎机可以理解为是强化学习问题的一个简化版，最主要的区别在于多臂老虎机问题不存在状态信息，只有动作和奖励，算是最简单的和环境交互中的学习问题。多臂老虎机中的**探索与利用**（exploration vs. exploitation）问题一直以来都是一个特别经典的问题，理解它能够帮助我们学习强化学习。

## 问题介绍

在多臂老虎机（multi-armed bandit，MAB）问题（见图 2-1）中，有一个拥有根拉杆的老虎机，拉动每一根拉杆都对应一个关于奖励的概率分布 。我们每次拉动其中一根拉杆，就可以从该拉杆对应的奖励概率分布中获得一个奖励 。我们在各根拉杆的奖励概率分布未知的情况下，从头开始尝试，目标是在操作 次拉杆后获得尽可能高的累积奖励。由于奖励的概率分布是未知的，因此我们需要在“探索拉杆的获奖概率”和“根据经验选择获奖最多的拉杆”中进行权衡。“采用怎样的操作策略才能使获得的累积奖励最高”便是多臂老虎机问题。如果是你，会怎么做呢？

